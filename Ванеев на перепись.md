### Токенизация - разделение текста на отдельные части
- по предложениям, например, через точку и пробел 
```regex
[.]\s
```
- по словам - через точку
### Стеннинг и лемматизация
### Стеннинг - поиск основы для заданного исходного текста. Без знания контекста. 
### Лемматизация - приведение значения слова к единому значению.
### Стоп-слова - удаление не несущих смысловой нагрузки, например, предлоги и союзы 
### н-грамма - последовательность из нескольких слов друг за другом
### коллокация - словосочетания, имеющие особый смысл (устойчивые выражения)
### векторное представление слов - тупой перевод вхождения каждого слова в вектор
Параметры:
- размерность вектора - количество координат вектора
- словарь токенов - уникальные слова/н-граммы в тексте
Создание векторов:
- тупой посчёт вхождений слова
#### мешок слов - игнорирует порядок слов

Схожесть мешка - глобальный контекст
Тональность предложения - отличия
Сложность увеличивается по мере роста словаря. Огромные такие векторы (с нулями) - разреженные
Методы уменьшения сложности:
- приведения к единой форме - лемме
- н-граммы (увеличение разряда в векторе)
### оценка
Скоринг - наличие слов. 
- Бинарный - есть слово или нет 
- Количественный - количество вхождений слова в предложении
- частотный - как часто входит по отношению к другим словам. Однако, слова с наибольшей вхождаемостью имеют наибольшую оценку. Для понижения используется TF-IDF, Term Frequency - Inverse Document Frequency - статическая мера
$$W_{x,y}=tf_{x,y}*log{N/df_x}$$
tf - отношение числа вхождений данного слова/общее число слов
idf - обратная tf, только в логарифме
получается, tf-idf - тупое их перемножение 
## эмбеддинг - преобразование чего-то абстрактного в набор чисел и векторов 
Векторное пространство - образуемая математическая структура векторами. Каждый вектор уникален, представляет собой представление объекта.
Размерность вектора - его количество координат в пространстве.
Расстояние между векторами - евклидово расстояние/косинусное сходство.
Евклидово расстояние - корень квадратный из суммы квадартов разностей по координатам
Косинусное сходство - угол между данными векторами. Угол -> 1 =>сходство довольно высокое.
#### методы
Word2vec - нейронные сети для составления векторов из слов
Состоит из:
- cbow - предсказание следующего слова по контексту. Continuous bag of words. Используется для создания эмбеддингов, анализа тональности, классификации слов и машинный перевод.
- skip-грамма - предсказание контекста по целевому слову. Её цель - изучение распределения вероятностей контекстных слов с учётом целевого слова. В ней используются следующие преобразователи в векторную форму:
	- быстрое кодирование (one-hot encoding), бинарное по вхождению в 
	- вектора вещественных 
## суммаризация текстов - вариант.