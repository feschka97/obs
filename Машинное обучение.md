## Машинное обучение состоит из: 
- ввод выборки
- извлечение признаков
- классификация
- получение результата
### Его составляющие:
- данные
- статистика
- расчёты
- другая информация для обучения
- признаки
- алгоритмы (для выбора наилучшего)
### Модель и процесс машинного обучения
[[Модель машинного обучения]] - функция/алгоритм, который даёт ответ/оценку ситуации по набору входных данных
## Обучение с учителем: 
- даём данные и ответ
- добавляем новые данные
### Учитель - изначальная [[Выборка|выборка]] с отмеченными нужным образом данными
## Обучение без учителя:
Используется при большом количестве некатегоризованных хаотичных данных
- машина сама находит связи между отдельными данными
- выявляет их закономерности
- подбирает шаблоны
- сортирует объекты в наборе данных
## Обучение с подкреплением:
### Подкрепление - создание связей
- машина обучается сама, методом проб и ошибок (данные при этом отсутствуют, но есть среда-генератор потока сигналов)
#### Задача: минимизация количества ошибок (поэтому последовательность успешных и неуспешных решений фиксируется)
## Глубокое обучение
### Глубокое обучение - подвид машинного обучения
Состоит из: 
- ввод данных
- извлечение признаков и классификация
- результат
Оно рассматривается как поиск услоаий, прик которых обучаемая модель в большинстве случаев начинает выдавать конкретные ответы. Использует датасеты
### Нейросети - подвид глубокого обучения
## Ансамбли
Ансамбли - объединение программ и их общее и исправление ошибок друг друга (например, распознавание предметов)


1. Выбор источника данных
2. Определение цели/метрики результатов
1+2. ETL - Extract, Transformer, Load- сборка, отчистка, объединение данных
3. EDA - Explorarory Data Analysis
1.₽++_+_ 
2. Данные конвертируются в формат
3. Данные загружаются в хранилище
### Процесс ветвей
1. Необработанные данные из различных источников извлекаются и помещаются в промежуточную область
Форматы разные, поэтому создаётся логическая карта данных. Они описывают свзяь данных с источниками данных и целевыми данными. 
1.еобходим проверить соответствие исходных данных
2. спам и нежелательные данные
3.соответствие данных целевому хранилищу
### способы извлечения данных
1 : источник уведомляет об изменении данных
2. Частичное извлечение без уведомления (источник может указывать на данные изменения)
3. Извлечение данных полное

### 2 шаг преобразование
На этом этапе необработанные данные
Устранение пропусков:
Интерполяция занчений ( заполнение близкими значения)
не работает с категориальными данными
Дедупликация (исключение лишних данных)
Стандартизация (преобразование разных типов данных к одному)
Проверка (удаление неиспользуемых данных и отметка аномалий)
Повторная сортировка столбцов и строк
Объединение данных из нескольких значений в одно
Дополнение данных из других источников
### 3 шаг (load)
Обработанные данные из промежуточной области загружаются в целевую базу хранилища
Варианты загрузки


2. Инкрементая загрузка (периодическая запись новых данных по мере необходимости)
3. Полное обновление таблицы (для последних данных)

преимущества ETL:
- экономия времени и автоматизация обработки данных
- упрощение работы со сложными данными
- снижение рисков из человеческого фактора
- улучшение процесса принятия решений и рентабельности инвестиций
Выбор формата обработки данных имеет приоритет
Масштабируемость данных

ELT - современный взгляд на ETL (поменяли буквы местами)
Внедрение ETL: 
- чёткое определение источников данных
- применение правил (агрегация, сортировка...)
- После преобразования данных их необходимо загружать с определённой периодичности
- Перемещение данных из хранилища
- автоматизация процесса ETL с помощью специальных инструментов
### EDA
Данный процесс выполняется единократно для каждой задачи машинного обучения
#### задачи EDA
1. Выбрать простейшую модель машинного обучения, выдающую наиболее точный результат
2. Поиск пропусков и преобразование их в адекватный вид
3. Определиться с наиболее важными параметрами
#### улучшение
1. Нахождение пропусков
2. Оценка параметров распредения данныхй
3. Корреляция между параметрами (для отсеивания ненужных)
4. Корреляция между предсказываемыми значениями
#### подготовка данных
Виды преобразования данных:
1. Нормирование (приведение к одному диапазону, чаще всего [0,1])
$$ x->\frac{x-x_{min}}{x_{max}-{x_{min}}}$$
-"- y
2. Категориальные данные (приведение к единичным векторам)
Для этого составляется идентификатор и назначается значение категорий
3. Преобразование циклических переменных
Применяют тригонометрические функции
### разбиение выборки
При машинном обучении данные разбиваются на 
- обучающие
- тестовые
- тренировочные
- валидационные наборы
Hold-out - данные разделяются на обучающие и тестовые выборки (SK_learn). Перед таким способом необходимо перемешивание данных.
Кросс-валидация (K_fold) (скользящий контроль)  - 
Статистический метод, используемый для оценки машинного обучения на независимых данных (процедура повторной выборки на ограниченной выборке данных)
Она имеет значение $k$ - количество групп, составляющих выборку данных, ([5-10]) - fold'ов
Шаги: 
1. перемешка датасета случайным образом
2. датасет разделяется на $k$-группы
3. Для каждой уникальной выборки:
	1. Берётся группа в качестве тестовой выборке
	2. Остальные группы - выборки учебных данных
	3. Подготовка модели на обучаемых выборках и её оценка на тестовой выборке
	4. Сохранение оценки модели и её отброс
Таким образом, модель учится на $k-1$ fold'е и тестирует на оставшемся.
4. Обобщение параметров качества модели с помощью выборки оценки модели
Окончательная модель обучения получается путём усреднения $k$ получившихся результатов.
### конфигурация $k$:
Он подбирается тчаиельнви образом
Подходы подбора:
- представитель - значение для него выбирается таким образом, что выборка достаточна велика
- $k≤10$ - было получено из экспериментальных исследований и обычно приводит к оценке качества модели с небольшой дисперсией (обычно 5/10)
- $k=n$ - $n$ - размер набора данных для дачи каждой тестовой группе возможность быть использованной в наборе данных
### вариации кросс-валидации:
1. Обучение/тестовая выборка (одна выборка идёт на обучение, другая на тест для оценки модели)
2. LoocV - $k=$ общему размеру наблюдений в датасете (leave one out)
3. Повторяющаяся выборка - $k$-фолд перекрёстная выборка повторяется $n$ раз и датасет перетасовывается каждый раз