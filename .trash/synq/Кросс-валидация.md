или же $k$-fold, скользящий контроль 
[[Кросс-валидация]] - статистический метод, используемый для оценки [[Машинное обучение|машинного обучения]] на независимых данных (процедура повторной [[Выборка|выборки]] на ограниченной [[Выборка|выборке]] данных)
Используется для оптимизации модели относительно себя самой.
Значение $k$ - количество групп ([фолдов]), составляющих выборку данных, обычно 5-10
Шаги: 
1. Перемешка датасета случайным образом
2. Датасет разделяется на $k$-группы
3. Для каждой уникальной выборки:
	1. Берётся группа в качестве тестовой выборке
	2. Остальные группы - выборки учебных данных
	3. Подготовка модели на обучаемых выборках и её оценка на тестовой выборке
	4. Сохранение оценки модели и её отброс
Таким образом, модель учится на $k-1$ фолд'ах и тестирует её на оставшемся.
4. Обобщение параметров качества модели с помощью выборки оценки модели
Окончательная модель обучения получается путём усреднения $k$ получившихся результатов.
### Конфигурация $k$:
Он подбирается тчательным образом:
Подходы подбора:
- представитель - значение для него выбирается таким образом, что выборка достаточна велика
- $k≤10$ - было получено из экспериментальных исследований и обычно приводит к оценке качества модели с небольшой дисперсией (обычно 5/10)
- $k=n$,  $n$ - размер набора данных для дачи каждой тестовой группе возможность быть использованной в наборе данных
### Вариации кросс-валидации:
1. Обучение/тестовая выборка (одна выборка идёт на обучение, другая на тест для оценки модели)
2. LoocV - $k=$ общему размеру наблюдений в датасете (leave one out)
3. Повторяющаяся выборка - $k$-фолд перекрёстная выборка повторяется $n$ раз и датасет перетасовывается каждый раз